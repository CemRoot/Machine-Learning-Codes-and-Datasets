# ğŸ¤– Machine Learning Codes and Datasets

<div align="center">

![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)
![R](https://img.shields.io/badge/R-4.0+-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Contributions](https://img.shields.io/badge/Contributions-Welcome-brightgreen.svg)
![Stars](https://img.shields.io/github/stars/CemRoot/Machine-Learning-Codes-and-Datasets?style=social)

**A comprehensive collection of machine learning algorithms, datasets, and implementations**

[English](#english) | [TÃ¼rkÃ§e](#turkce)

</div>

---

<a name="english"></a>

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Repository Structure](#repository-structure)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Usage](#usage)
- [Algorithms Covered](#algorithms-covered)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgments](#acknowledgments)

## ğŸ¯ Overview

Welcome to the **Machine Learning Codes and Datasets** repository! This comprehensive resource is designed for machine learning practitioners, students, and enthusiasts who want to learn, practice, and master various ML algorithms and techniques.

### ğŸ“ What You Will Learn

- âœ… Implementation of **40+ machine learning algorithms** from scratch
- âœ… Data preprocessing and feature engineering techniques
- âœ… Model evaluation and performance optimization
- âœ… Deep learning with neural networks
- âœ… Natural language processing fundamentals
- âœ… Dimensionality reduction methods
- âœ… Best practices in machine learning workflows

## â­ Features

- ğŸ“š **Comprehensive Coverage**: 11 major ML domains with 40+ algorithms
- ğŸ’» **Dual Language Support**: Python and R implementations
- ğŸ“Š **Real-world Datasets**: Curated datasets for each algorithm
- ğŸ“ **Interactive Notebooks**: Jupyter notebooks with detailed explanations
- ğŸ”¬ **Production-ready Code**: Clean, documented, and modular code
- ğŸ¨ **Visualization**: Beautiful plots and charts for better understanding
- ğŸŒ **Bilingual Documentation**: Full English and Turkish support

## ğŸ“ Repository Structure

```
Machine-Learning-Codes-and-Datasets/
â”‚
â”œâ”€â”€ Part 1 - Data Preprocessing/
â”‚   â””â”€â”€ Data cleaning, transformation, and feature scaling
â”‚
â”œâ”€â”€ Part 2 - Regression/
â”‚   â”œâ”€â”€ Simple Linear Regression
â”‚   â”œâ”€â”€ Multiple Linear Regression
â”‚   â”œâ”€â”€ Polynomial Regression
â”‚   â”œâ”€â”€ Support Vector Regression (SVR)
â”‚   â”œâ”€â”€ Decision Tree Regression
â”‚   â””â”€â”€ Random Forest Regression
â”‚
â”œâ”€â”€ Part 3 - Classification/
â”‚   â”œâ”€â”€ Logistic Regression
â”‚   â”œâ”€â”€ K-Nearest Neighbors (K-NN)
â”‚   â”œâ”€â”€ Support Vector Machine (SVM)
â”‚   â”œâ”€â”€ Kernel SVM
â”‚   â”œâ”€â”€ Naive Bayes
â”‚   â”œâ”€â”€ Decision Tree Classification
â”‚   â””â”€â”€ Random Forest Classification
â”‚
â”œâ”€â”€ Part 4 - Clustering/
â”‚   â”œâ”€â”€ K-Means Clustering
â”‚   â””â”€â”€ Hierarchical Clustering
â”‚
â”œâ”€â”€ Part 5 - Association Rule Learning/
â”‚   â”œâ”€â”€ Apriori Algorithm
â”‚   â””â”€â”€ Eclat Algorithm
â”‚
â”œâ”€â”€ Part 6 - Reinforcement Learning/
â”‚   â”œâ”€â”€ Upper Confidence Bound (UCB)
â”‚   â””â”€â”€ Thompson Sampling
â”‚
â”œâ”€â”€ Part 7 - Natural Language Processing/
â”‚   â””â”€â”€ Text preprocessing and sentiment analysis
â”‚
â”œâ”€â”€ Part 8 - Deep Learning/
â”‚   â”œâ”€â”€ Artificial Neural Networks (ANN)
â”‚   â””â”€â”€ Convolutional Neural Networks (CNN)
â”‚
â”œâ”€â”€ Part 9 - Dimensionality Reduction/
â”‚   â”œâ”€â”€ Principal Component Analysis (PCA)
â”‚   â”œâ”€â”€ Linear Discriminant Analysis (LDA)
â”‚   â””â”€â”€ Kernel PCA
â”‚
â”œâ”€â”€ Part 10 - Model Selection & Boosting/
â”‚   â”œâ”€â”€ k-Fold Cross Validation
â”‚   â”œâ”€â”€ Grid Search
â”‚   â””â”€â”€ XGBoost
â”‚
â””â”€â”€ ML_cheatsheet.pdf
```

## ğŸ”§ Prerequisites

Before you begin, ensure you have the following installed:

- **Python**: 3.7 or higher
- **R**: 4.0 or higher (optional, for R implementations)
- **pip**: Python package manager
- **Git**: Version control system

### Required Knowledge

- Basic understanding of Python programming
- Fundamentals of linear algebra and statistics
- Familiarity with NumPy and Pandas (recommended)

## ğŸš€ Installation

### Step 1: Clone the Repository

```bash
git clone https://github.com/CemRoot/Machine-Learning-Codes-and-Datasets.git
cd Machine-Learning-Codes-and-Datasets
```

### Step 2: Create a Virtual Environment (Recommended)

```bash
# For Python venv
python -m venv ml_env
source ml_env/bin/activate  # On Windows: ml_env\Scripts\activate

# OR using Conda
conda create -n ml_env python=3.9
conda activate ml_env
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 4: Launch Jupyter Notebook

```bash
jupyter notebook
```

## ğŸ’¡ Usage

### Quick Start Example

Here's a simple example of using linear regression from this repository:

```python
# Import required libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# Load dataset
dataset = pd.read_csv('Salary_Data.csv')
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Train model
regressor = LinearRegression()
regressor.fit(X_train, y_train)

# Make predictions
y_pred = regressor.predict(X_test)

# Visualize results
plt.scatter(X_test, y_test, color='red')
plt.plot(X_test, y_pred, color='blue')
plt.title('Salary vs Experience')
plt.xlabel('Years of Experience')
plt.ylabel('Salary')
plt.show()
```

### Running Individual Algorithms

Navigate to the specific algorithm directory and run the Python script or Jupyter notebook:

```bash
# Example: Running K-Means Clustering
cd "Part 4 - Clustering/Section 24 - K-Means Clustering/Python"
python k_means_clustering.py

# Or open the Jupyter notebook
jupyter notebook k_means_clustering.ipynb
```

## ğŸ§  Algorithms Covered

<details>
<summary><b>Part 1: Data Preprocessing</b></summary>

- Handling Missing Data
- Encoding Categorical Data
- Feature Scaling (Standardization & Normalization)
- Train/Test Split

</details>

<details>
<summary><b>Part 2: Regression (6 Algorithms)</b></summary>

- Simple Linear Regression
- Multiple Linear Regression
- Polynomial Regression
- Support Vector Regression (SVR)
- Decision Tree Regression
- Random Forest Regression

</details>

<details>
<summary><b>Part 3: Classification (7 Algorithms)</b></summary>

- Logistic Regression
- K-Nearest Neighbors (K-NN)
- Support Vector Machine (SVM)
- Kernel SVM
- Naive Bayes
- Decision Tree Classification
- Random Forest Classification

</details>

<details>
<summary><b>Part 4: Clustering (2 Algorithms)</b></summary>

- K-Means Clustering
- Hierarchical Clustering

</details>

<details>
<summary><b>Part 5: Association Rule Learning (2 Algorithms)</b></summary>

- Apriori
- Eclat

</details>

<details>
<summary><b>Part 6: Reinforcement Learning (2 Algorithms)</b></summary>

- Upper Confidence Bound (UCB)
- Thompson Sampling

</details>

<details>
<summary><b>Part 7: Natural Language Processing</b></summary>

- Bag of Words Model
- Text Preprocessing
- Sentiment Analysis

</details>

<details>
<summary><b>Part 8: Deep Learning (2 Types)</b></summary>

- Artificial Neural Networks (ANN)
- Convolutional Neural Networks (CNN)

</details>

<details>
<summary><b>Part 9: Dimensionality Reduction (3 Algorithms)</b></summary>

- Principal Component Analysis (PCA)
- Linear Discriminant Analysis (LDA)
- Kernel PCA

</details>

<details>
<summary><b>Part 10: Model Selection & Boosting</b></summary>

- k-Fold Cross Validation
- Grid Search for Hyperparameter Tuning
- XGBoost

</details>

## ğŸ› ï¸ Tech Stack

| Technology | Purpose |
|------------|---------|
| ![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white) | Primary programming language |
| ![NumPy](https://img.shields.io/badge/NumPy-013243?style=flat&logo=numpy&logoColor=white) | Numerical computing |
| ![Pandas](https://img.shields.io/badge/Pandas-150458?style=flat&logo=pandas&logoColor=white) | Data manipulation |
| ![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-F7931E?style=flat&logo=scikit-learn&logoColor=white) | Machine learning algorithms |
| ![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=flat&logo=tensorflow&logoColor=white) | Deep learning framework |
| ![Keras](https://img.shields.io/badge/Keras-D00000?style=flat&logo=keras&logoColor=white) | Neural networks API |
| ![Matplotlib](https://img.shields.io/badge/Matplotlib-11557c?style=flat) | Data visualization |
| ![Jupyter](https://img.shields.io/badge/Jupyter-F37626?style=flat&logo=jupyter&logoColor=white) | Interactive notebooks |
| ![R](https://img.shields.io/badge/R-276DC3?style=flat&logo=r&logoColor=white) | Statistical computing |

## ğŸ¤ Contributing

We welcome contributions from the community! Here's how you can help:

1. **Fork** the repository
2. **Create** a new branch (`git checkout -b feature/AmazingFeature`)
3. **Commit** your changes (`git commit -m 'Add some AmazingFeature'`)
4. **Push** to the branch (`git push origin feature/AmazingFeature`)
5. **Open** a Pull Request

Please read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.

### Ways to Contribute

- ğŸ› Report bugs and issues
- ğŸ’¡ Suggest new features or algorithms
- ğŸ“ Improve documentation
- ğŸ§ª Add new datasets
- âœ¨ Enhance existing implementations
- ğŸŒ Translate documentation

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Inspired by various machine learning courses and resources
- Thanks to all contributors who have helped improve this repository
- Special thanks to the open-source ML community

## ğŸ“ Contact & Support

- **Repository**: [GitHub](https://github.com/CemRoot/Machine-Learning-Codes-and-Datasets)
- **Issues**: [Report a Bug](https://github.com/CemRoot/Machine-Learning-Codes-and-Datasets/issues)
- **Discussions**: [Join the Discussion](https://github.com/CemRoot/Machine-Learning-Codes-and-Datasets/discussions)

---

<div align="center">

### â­ Star this repository if you find it helpful!

If this repository helped you in your machine learning journey, please consider giving it a star â­

**Happy Learning! ğŸš€**

</div>

---

<a name="turkce"></a>

## ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e DokÃ¼mantasyon

## ğŸ“‹ Ä°Ã§indekiler

- [Genel BakÄ±ÅŸ](#genel-bakÄ±ÅŸ)
- [Ã–zellikler](#Ã¶zellikler)
- [Depo YapÄ±sÄ±](#depo-yapÄ±sÄ±)
- [Gereksinimler](#gereksinimler)
- [Kurulum](#kurulum)
- [KullanÄ±m](#kullanÄ±m)
- [Kapsanan Algoritmalar](#kapsanan-algoritmalar)
- [KatkÄ±da Bulunma](#katkÄ±da-bulunma)
- [Lisans](#lisans)

## ğŸ¯ Genel BakÄ±ÅŸ

**Makine Ã–ÄŸrenmesi KodlarÄ± ve Veri Setleri** deposuna hoÅŸ geldiniz! Bu kapsamlÄ± kaynak, makine Ã¶ÄŸrenmesi uygulayÄ±cÄ±larÄ±, Ã¶ÄŸrenciler ve meraklÄ±larÄ± iÃ§in Ã§eÅŸitli ML algoritmalarÄ±nÄ± ve tekniklerini Ã¶ÄŸrenmek, pratik yapmak ve ustalaÅŸmak iÃ§in tasarlanmÄ±ÅŸtÄ±r.

### ğŸ“ Neler Ã–ÄŸreneceksiniz

- âœ… **40+ makine Ã¶ÄŸrenmesi algoritmasÄ±nÄ±n** sÄ±fÄ±rdan implementasyonu
- âœ… Veri Ã¶n iÅŸleme ve Ã¶zellik mÃ¼hendisliÄŸi teknikleri
- âœ… Model deÄŸerlendirme ve performans optimizasyonu
- âœ… Sinir aÄŸlarÄ± ile derin Ã¶ÄŸrenme
- âœ… DoÄŸal dil iÅŸleme temelleri
- âœ… Boyut azaltma yÃ¶ntemleri
- âœ… Makine Ã¶ÄŸrenmesi iÅŸ akÄ±ÅŸlarÄ±nda en iyi uygulamalar

## â­ Ã–zellikler

- ğŸ“š **KapsamlÄ± Kapsam**: 40+ algoritma ile 11 ana ML alanÄ±
- ğŸ’» **Ã‡ift Dil DesteÄŸi**: Python ve R implementasyonlarÄ±
- ğŸ“Š **GerÃ§ek DÃ¼nya Veri Setleri**: Her algoritma iÃ§in Ã¶zenle seÃ§ilmiÅŸ veri setleri
- ğŸ“ **EtkileÅŸimli Notebook'lar**: DetaylÄ± aÃ§Ä±klamalÄ± Jupyter notebook'larÄ±
- ğŸ”¬ **Ãœretime HazÄ±r Kod**: Temiz, dokÃ¼mante edilmiÅŸ ve modÃ¼ler kod
- ğŸ¨ **GÃ¶rselleÅŸtirme**: Daha iyi anlama iÃ§in gÃ¼zel grafikler ve Ã§izelgeler
- ğŸŒ **Ä°ki Dilli DokÃ¼mantasyon**: Tam Ä°ngilizce ve TÃ¼rkÃ§e destek

## ğŸ“ Depo YapÄ±sÄ±

```
Machine-Learning-Codes-and-Datasets/
â”‚
â”œâ”€â”€ Part 1 - Veri Ã–n Ä°ÅŸleme/
â”‚   â””â”€â”€ Veri temizleme, dÃ¶nÃ¼ÅŸtÃ¼rme ve Ã¶zellik Ã¶lÃ§eklendirme
â”‚
â”œâ”€â”€ Part 2 - Regresyon/
â”‚   â”œâ”€â”€ Basit DoÄŸrusal Regresyon
â”‚   â”œâ”€â”€ Ã‡oklu DoÄŸrusal Regresyon
â”‚   â”œâ”€â”€ Polinom Regresyon
â”‚   â”œâ”€â”€ Destek VektÃ¶r Regresyonu (SVR)
â”‚   â”œâ”€â”€ Karar AÄŸacÄ± Regresyonu
â”‚   â””â”€â”€ Rastgele Orman Regresyonu
â”‚
â”œâ”€â”€ Part 3 - SÄ±nÄ±flandÄ±rma/
â”‚   â”œâ”€â”€ Lojistik Regresyon
â”‚   â”œâ”€â”€ K-En YakÄ±n KomÅŸu (K-NN)
â”‚   â”œâ”€â”€ Destek VektÃ¶r Makinesi (SVM)
â”‚   â”œâ”€â”€ Kernel SVM
â”‚   â”œâ”€â”€ Naive Bayes
â”‚   â”œâ”€â”€ Karar AÄŸacÄ± SÄ±nÄ±flandÄ±rmasÄ±
â”‚   â””â”€â”€ Rastgele Orman SÄ±nÄ±flandÄ±rmasÄ±
â”‚
â”œâ”€â”€ Part 4 - KÃ¼meleme/
â”‚   â”œâ”€â”€ K-Means KÃ¼meleme
â”‚   â””â”€â”€ HiyerarÅŸik KÃ¼meleme
â”‚
â”œâ”€â”€ Part 5 - Birliktelik KuralÄ± Ã–ÄŸrenimi/
â”‚   â”œâ”€â”€ Apriori AlgoritmasÄ±
â”‚   â””â”€â”€ Eclat AlgoritmasÄ±
â”‚
â”œâ”€â”€ Part 6 - PekiÅŸtirmeli Ã–ÄŸrenme/
â”‚   â”œâ”€â”€ Ãœst GÃ¼ven SÄ±nÄ±rÄ± (UCB)
â”‚   â””â”€â”€ Thompson Ã–rneklemesi
â”‚
â”œâ”€â”€ Part 7 - DoÄŸal Dil Ä°ÅŸleme/
â”‚   â””â”€â”€ Metin Ã¶n iÅŸleme ve duygu analizi
â”‚
â”œâ”€â”€ Part 8 - Derin Ã–ÄŸrenme/
â”‚   â”œâ”€â”€ Yapay Sinir AÄŸlarÄ± (ANN)
â”‚   â””â”€â”€ EvriÅŸimli Sinir AÄŸlarÄ± (CNN)
â”‚
â”œâ”€â”€ Part 9 - Boyut Azaltma/
â”‚   â”œâ”€â”€ Temel BileÅŸen Analizi (PCA)
â”‚   â”œâ”€â”€ DoÄŸrusal Diskriminant Analizi (LDA)
â”‚   â””â”€â”€ Kernel PCA
â”‚
â”œâ”€â”€ Part 10 - Model SeÃ§imi ve GÃ¼Ã§lendirme/
â”‚   â”œâ”€â”€ k-KatlÄ± Ã‡apraz DoÄŸrulama
â”‚   â”œâ”€â”€ Izgara AramasÄ±
â”‚   â””â”€â”€ XGBoost
â”‚
â””â”€â”€ ML_cheatsheet.pdf
```

## ğŸ”§ Gereksinimler

BaÅŸlamadan Ã¶nce, aÅŸaÄŸÄ±dakilerin yÃ¼klÃ¼ olduÄŸundan emin olun:

- **Python**: 3.7 veya Ã¼zeri
- **R**: 4.0 veya Ã¼zeri (opsiyonel, R implementasyonlarÄ± iÃ§in)
- **pip**: Python paket yÃ¶neticisi
- **Git**: Versiyon kontrol sistemi

### Gerekli Bilgi

- Python programlama temel bilgisi
- Lineer cebir ve istatistik temelleri
- NumPy ve Pandas bilgisi (Ã¶nerilir)

## ğŸš€ Kurulum

### AdÄ±m 1: Depoyu KlonlayÄ±n

```bash
git clone https://github.com/CemRoot/Machine-Learning-Codes-and-Datasets.git
cd Machine-Learning-Codes-and-Datasets
```

### AdÄ±m 2: Sanal Ortam OluÅŸturun (Ã–nerilir)

```bash
# Python venv iÃ§in
python -m venv ml_env
source ml_env/bin/activate  # Windows'ta: ml_env\Scripts\activate

# VEYA Conda kullanarak
conda create -n ml_env python=3.9
conda activate ml_env
```

### AdÄ±m 3: BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin

```bash
pip install -r requirements.txt
```

### AdÄ±m 4: Jupyter Notebook'u BaÅŸlatÄ±n

```bash
jupyter notebook
```

## ğŸ’¡ KullanÄ±m

### HÄ±zlÄ± BaÅŸlangÄ±Ã§ Ã–rneÄŸi

Bu depodan lineer regresyon kullanÄ±mÄ±na dair basit bir Ã¶rnek:

```python
# Gerekli kÃ¼tÃ¼phaneleri iÃ§e aktarÄ±n
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# Veri setini yÃ¼kleyin
dataset = pd.read_csv('Salary_Data.csv')
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values

# Veri setini bÃ¶lÃ¼n
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Modeli eÄŸitin
regressor = LinearRegression()
regressor.fit(X_train, y_train)

# Tahmin yapÄ±n
y_pred = regressor.predict(X_test)

# SonuÃ§larÄ± gÃ¶rselleÅŸtirin
plt.scatter(X_test, y_test, color='red')
plt.plot(X_test, y_pred, color='blue')
plt.title('MaaÅŸ vs Deneyim')
plt.xlabel('Deneyim YÄ±lÄ±')
plt.ylabel('MaaÅŸ')
plt.show()
```

### Tekil AlgoritmalarÄ± Ã‡alÄ±ÅŸtÄ±rma

Belirli bir algoritma dizinine gidin ve Python scriptini veya Jupyter notebook'unu Ã§alÄ±ÅŸtÄ±rÄ±n:

```bash
# Ã–rnek: K-Means KÃ¼meleme Ã§alÄ±ÅŸtÄ±rma
cd "Part 4 - Clustering/Section 24 - K-Means Clustering/Python"
python k_means_clustering.py

# Veya Jupyter notebook'u aÃ§Ä±n
jupyter notebook k_means_clustering.ipynb
```

## ğŸ§  Kapsanan Algoritmalar

<details>
<summary><b>BÃ¶lÃ¼m 1: Veri Ã–n Ä°ÅŸleme</b></summary>

- Eksik Verilerin Ä°ÅŸlenmesi
- Kategorik Verilerin KodlanmasÄ±
- Ã–zellik Ã–lÃ§eklendirme (Standardizasyon ve Normalizasyon)
- EÄŸitim/Test AyrÄ±mÄ±

</details>

<details>
<summary><b>BÃ¶lÃ¼m 2: Regresyon (6 Algoritma)</b></summary>

- Basit DoÄŸrusal Regresyon
- Ã‡oklu DoÄŸrusal Regresyon
- Polinom Regresyon
- Destek VektÃ¶r Regresyonu (SVR)
- Karar AÄŸacÄ± Regresyonu
- Rastgele Orman Regresyonu

</details>

<details>
<summary><b>BÃ¶lÃ¼m 3: SÄ±nÄ±flandÄ±rma (7 Algoritma)</b></summary>

- Lojistik Regresyon
- K-En YakÄ±n KomÅŸu (K-NN)
- Destek VektÃ¶r Makinesi (SVM)
- Kernel SVM
- Naive Bayes
- Karar AÄŸacÄ± SÄ±nÄ±flandÄ±rmasÄ±
- Rastgele Orman SÄ±nÄ±flandÄ±rmasÄ±

</details>

<details>
<summary><b>BÃ¶lÃ¼m 4: KÃ¼meleme (2 Algoritma)</b></summary>

- K-Means KÃ¼meleme
- HiyerarÅŸik KÃ¼meleme

</details>

<details>
<summary><b>BÃ¶lÃ¼m 5: Birliktelik KuralÄ± Ã–ÄŸrenimi (2 Algoritma)</b></summary>

- Apriori
- Eclat

</details>

<details>
<summary><b>BÃ¶lÃ¼m 6: PekiÅŸtirmeli Ã–ÄŸrenme (2 Algoritma)</b></summary>

- Ãœst GÃ¼ven SÄ±nÄ±rÄ± (UCB)
- Thompson Ã–rneklemesi

</details>

<details>
<summary><b>BÃ¶lÃ¼m 7: DoÄŸal Dil Ä°ÅŸleme</b></summary>

- Kelime Ã‡antasÄ± Modeli
- Metin Ã–n Ä°ÅŸleme
- Duygu Analizi

</details>

<details>
<summary><b>BÃ¶lÃ¼m 8: Derin Ã–ÄŸrenme (2 Tip)</b></summary>

- Yapay Sinir AÄŸlarÄ± (ANN)
- EvriÅŸimli Sinir AÄŸlarÄ± (CNN)

</details>

<details>
<summary><b>BÃ¶lÃ¼m 9: Boyut Azaltma (3 Algoritma)</b></summary>

- Temel BileÅŸen Analizi (PCA)
- DoÄŸrusal Diskriminant Analizi (LDA)
- Kernel PCA

</details>

<details>
<summary><b>BÃ¶lÃ¼m 10: Model SeÃ§imi ve GÃ¼Ã§lendirme</b></summary>

- k-KatlÄ± Ã‡apraz DoÄŸrulama
- Hiperparametre AyarÄ± iÃ§in Izgara AramasÄ±
- XGBoost

</details>

## ğŸ¤ KatkÄ±da Bulunma

Topluluktan katkÄ±larÄ± memnuniyetle karÅŸÄ±lÄ±yoruz! Ä°ÅŸte nasÄ±l yardÄ±mcÄ± olabilirsiniz:

1. Depoyu **Fork** edin
2. Yeni bir branch **oluÅŸturun** (`git checkout -b feature/HarikaBirOzellik`)
3. DeÄŸiÅŸikliklerinizi **commit** edin (`git commit -m 'Harika bir Ã¶zellik ekle'`)
4. Branch'e **push** yapÄ±n (`git push origin feature/HarikaBirOzellik`)
5. Bir Pull Request **aÃ§Ä±n**

DavranÄ±ÅŸ kurallarÄ±mÄ±z ve pull request gÃ¶nderme sÃ¼reci hakkÄ±nda detaylar iÃ§in lÃ¼tfen [CONTRIBUTING.md](CONTRIBUTING.md) dosyasÄ±nÄ± okuyun.

### KatkÄ± YollarÄ±

- ğŸ› Hata ve sorunlarÄ± bildirin
- ğŸ’¡ Yeni Ã¶zellikler veya algoritmalar Ã¶nerin
- ğŸ“ DokÃ¼mantasyonu geliÅŸtirin
- ğŸ§ª Yeni veri setleri ekleyin
- âœ¨ Mevcut implementasyonlarÄ± iyileÅŸtirin
- ğŸŒ DokÃ¼mantasyonu Ã§evirin

## ğŸ“„ Lisans

Bu proje MIT LisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r - detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.

## ğŸ™ TeÅŸekkÃ¼rler

- Ã‡eÅŸitli makine Ã¶ÄŸrenmesi kurslarÄ± ve kaynaklarÄ±ndan esinlenilmiÅŸtir
- Bu depoyu geliÅŸtirmeye yardÄ±mcÄ± olan tÃ¼m katkÄ±da bulunanlara teÅŸekkÃ¼rler
- AÃ§Ä±k kaynak ML topluluÄŸuna Ã¶zel teÅŸekkÃ¼rler

## ğŸ“ Ä°letiÅŸim ve Destek

- **Depo**: [GitHub](https://github.com/CemRoot/Machine-Learning-Codes-and-Datasets)
- **Sorunlar**: [Hata Bildirin](https://github.com/CemRoot/Machine-Learning-Codes-and-Datasets/issues)
- **TartÄ±ÅŸmalar**: [TartÄ±ÅŸmaya KatÄ±lÄ±n](https://github.com/CemRoot/Machine-Learning-Codes-and-Datasets/discussions)

---

<div align="center">

### â­ FaydalÄ± bulduysanÄ±z bu depoyu yÄ±ldÄ±zlayÄ±n!

Bu depo makine Ã¶ÄŸrenmesi yolculuÄŸunuzda size yardÄ±mcÄ± olduysa, lÃ¼tfen bir yÄ±ldÄ±z vermeyi dÃ¼ÅŸÃ¼nÃ¼n â­

**Mutlu Ã–ÄŸrenmeler! ğŸš€**

</div>

---

## ğŸ“ˆ Project Stats

![GitHub last commit](https://img.shields.io/github/last-commit/CemRoot/Machine-Learning-Codes-and-Datasets)
![GitHub issues](https://img.shields.io/github/issues/CemRoot/Machine-Learning-Codes-and-Datasets)
![GitHub pull requests](https://img.shields.io/github/issues-pr/CemRoot/Machine-Learning-Codes-and-Datasets)
![GitHub forks](https://img.shields.io/github/forks/CemRoot/Machine-Learning-Codes-and-Datasets?style=social)

---

<div align="center">

**Made with â¤ï¸ for the Machine Learning Community**

</div>

{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "convolutional_neural_network.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DR-eO17geWu",
    "colab_type": "text"
   },
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMefrVPCg-60",
    "colab_type": "text"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sCV30xyVhFbE",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "end_time": "2025-05-05T22:31:01.753691Z",
     "start_time": "2025-05-05T22:31:01.738039Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import image_dataset_from_directory, load_img, img_to_array"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FIleuCAjoFD8",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "end_time": "2025-05-05T22:31:09.320180Z",
     "start_time": "2025-05-05T22:31:09.317727Z"
    }
   },
   "source": [
    "tf.__version__"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.19.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxQxCBWyoGPE",
    "colab_type": "text"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvE-heJNo3GG",
    "colab_type": "text"
   },
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0koUcJMJpEBD",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "end_time": "2025-05-05T22:31:11.675372Z",
     "start_time": "2025-05-05T22:31:11.580458Z"
    }
   },
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/training_set'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m train_datagen \u001B[38;5;241m=\u001B[39m ImageDataGenerator(rescale \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m255\u001B[39m,\n\u001B[1;32m      2\u001B[0m                                    shear_range \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.2\u001B[39m,\n\u001B[1;32m      3\u001B[0m                                    zoom_range \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.2\u001B[39m,\n\u001B[1;32m      4\u001B[0m                                    horizontal_flip \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 5\u001B[0m training_set \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_datagen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflow_from_directory\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdataset/training_set\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mtarget_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mclass_mode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbinary\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py:1138\u001B[0m, in \u001B[0;36mImageDataGenerator.flow_from_directory\u001B[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001B[0m\n\u001B[1;32m   1120\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mflow_from_directory\u001B[39m(\n\u001B[1;32m   1121\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1122\u001B[0m     directory,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1136\u001B[0m     keep_aspect_ratio\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m   1137\u001B[0m ):\n\u001B[0;32m-> 1138\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDirectoryIterator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1139\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1140\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1141\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1142\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolor_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolor_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1143\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeep_aspect_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_aspect_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1144\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclasses\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclasses\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1145\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1146\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1147\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1148\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1149\u001B[0m \u001B[43m        \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1150\u001B[0m \u001B[43m        \u001B[49m\u001B[43msave_to_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_to_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1151\u001B[0m \u001B[43m        \u001B[49m\u001B[43msave_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1152\u001B[0m \u001B[43m        \u001B[49m\u001B[43msave_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1153\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfollow_links\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_links\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1154\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1155\u001B[0m \u001B[43m        \u001B[49m\u001B[43minterpolation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterpolation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1157\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py:453\u001B[0m, in \u001B[0;36mDirectoryIterator.__init__\u001B[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001B[0m\n\u001B[1;32m    451\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m classes:\n\u001B[1;32m    452\u001B[0m     classes \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m--> 453\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m subdir \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m)\u001B[49m):\n\u001B[1;32m    454\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(directory, subdir)):\n\u001B[1;32m    455\u001B[0m             classes\u001B[38;5;241m.\u001B[39mappend(subdir)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'dataset/training_set'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrCMmGw9pHys",
    "colab_type": "text"
   },
   "source": [
    "### Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SH4WzfOhpKc3",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af8O4l90gk7B",
    "colab_type": "text"
   },
   "source": [
    "## Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ces1gXY2lmoX",
    "colab_type": "text"
   },
   "source": [
    "### Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SAUt4UMPlhLS",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5YJj_XMl5LF",
    "colab_type": "text"
   },
   "source": [
    "### Step 1 - Convolution"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XPzPrMckl-hV",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tf87FpvxmNOJ",
    "colab_type": "text"
   },
   "source": [
    "### Step 2 - Pooling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ncpqPl69mOac",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaTOgD8rm4mU",
    "colab_type": "text"
   },
   "source": [
    "### Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i_-FZjn_m8gk",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmiEuvTunKfk",
    "colab_type": "text"
   },
   "source": [
    "### Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6AZeOGCvnNZn",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAoSECOm203v",
    "colab_type": "text"
   },
   "source": [
    "### Step 4 - Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8GtmUlLd26Nq",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTldFvbX28Na",
    "colab_type": "text"
   },
   "source": [
    "### Step 5 - Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1p_Zj1Mc3Ko_",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6XkI90snSDl",
    "colab_type": "text"
   },
   "source": [
    "## Part 3 - Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfrFQACEnc6i",
    "colab_type": "text"
   },
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NALksrNQpUlJ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehS-v3MIpX2h",
    "colab_type": "text"
   },
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XUj1W4PJptta",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3PZasO0006Z",
    "colab_type": "text"
   },
   "source": [
    "## Part 4 - Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gsSiWEJY1BPB",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "  prediction = 'dog'\n",
    "else:\n",
    "  prediction = 'cat'"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ED9KB3I54c1i",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "print(prediction)"
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}
